{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Winning Jeopardy with Data\n",
    "\n",
    "In this notebook I'm going to work with a dataset of jeopardy questions with their values and answers. I'll try to find some patterns in the questions.\n",
    "\n",
    "Let's take a quick look and see what data we have. Here are the first 5 of 20,000 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "jeopardy = pd.read_csv('jeopardy.csv')\n",
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the column names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
       "       ' Question', ' Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that some of the column names have leading spaces. Just going to clean this up a little bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question',\n",
       "       'Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.columns = jeopardy.columns.str.strip()\n",
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see the column names are fixed - no pesky extra spaces. The next bit of normalization for any text analysis is to fix up the question and answer columns. Make everything lowercase, remove punctuation, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function that turns everything lowercase and removes\n",
    "# all punctuation\n",
    "def normalize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"[^A-Za-z0-9\\s]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "# normalize the question and answer columns\n",
    "jeopardy['clean_question'] = jeopardy['Question'].apply(normalize)\n",
    "jeopardy['clean_answer'] = jeopardy['Answer'].apply(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The next bit of normalization is to make the numeric columns properly numeric. That is, for the column of dollar values, we want to remove all dollar signs and convert it to numeric. We also want to make the the air date column a proper date, not a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_vals(text):\n",
    "    text = re.sub(\"[^A-Za-z0-9\\s]\", \"\", text)\n",
    "    try:\n",
    "        text = int(text)\n",
    "    except:\n",
    "        text = 0\n",
    "    return text\n",
    "\n",
    "jeopardy[\"clean_value\"] = jeopardy[\"Value\"].apply(normalize_vals)\n",
    "\n",
    "# convert air date to a datetime object\n",
    "jeopardy['Air Date'] = pd.to_datetime(jeopardy['Air Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two questions we are going to peruse with these cleaned up data are how often the answer can be deduced from the question, and how often new questions are repeats of older questions.\n",
    "\n",
    "The first question can be tested by seeing how often the answer of the question actually appears in the question text. The second question can be answered by seeing how often complex words occur (e.g., words longer than six characters).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function will count all the matches. If an answer\n",
    "# appears in a question\n",
    "def matches(row):\n",
    "    split_answer = row[\"clean_answer\"].split(\" \")\n",
    "    split_question = row[\"clean_question\"].split(\" \")\n",
    "    match_count = 0\n",
    "    if \"the\" in split_answer:\n",
    "        split_answer.remove(\"the\")\n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "    for elt in split_answer:\n",
    "        if elt in split_question:\n",
    "            match_count += 1\n",
    "    return match_count / len(split_answer)\n",
    "\n",
    "jeopardy['answer_in_question'] = jeopardy.apply(matches,\n",
    "                                                axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.060493257069335872"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['answer_in_question'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in answering the first question we see that the answer cannot be inferred from the question very often. Only 6% of the time does the answer actually appear in the question. This makes total sense, because why would they \"give away\" the answer more than occasionally?\n",
    "\n",
    "Let's investigate the second question. How often are complex words repeated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69259600573386471"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_overlap = []\n",
    "terms_used = set()\n",
    "\n",
    "for i, row in jeopardy.iterrows():\n",
    "    split_question = row[\"clean_question\"].split(\" \")\n",
    "    split_question = [q for q in split_question if len(q) > 5]\n",
    "    match_count = 0\n",
    "    for elt in split_question:\n",
    "        if elt in terms_used:\n",
    "            match_count += 1\n",
    "        terms_used.add(elt)\n",
    "    if len(split_question) > 0:\n",
    "        match_count /= len(split_question)\n",
    "    question_overlap.append(match_count)\n",
    "\n",
    "jeopardy['question_overlap'] = question_overlap \n",
    "jeopardy['question_overlap'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so these data suggest that about 70% of the time words have appeared in previous questions. That is, jeopardy very often recycles questions so we could really streamline our studying by just studying previous questions. We've only got a small subset of data, and we're only looking at recycled terms not recycled phrases, so take it with a grain of salt but suggests further investigation into recycled questions is warranted.\n",
    "\n",
    "The last little bit I'm going to explore here is what words most frequently appear in high or low values questions, defined as above and below $800, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (0, 1), (0, 1), (1, 0), (0, 1)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function assigns high and low value indicators\n",
    "def determine_value(row):\n",
    "    value = 0\n",
    "    if row[\"clean_value\"] > 800:\n",
    "        value = 1\n",
    "    return value\n",
    "\n",
    "jeopardy[\"high_value\"] = jeopardy.apply(determine_value, axis=1)\n",
    "# Function that counts words in high and low val questions\n",
    "def count_usage(term):\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for i, row in jeopardy.iterrows():\n",
    "        if term in row[\"clean_question\"].split(\" \"):\n",
    "            if row[\"high_value\"] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    return high_count, low_count\n",
    "\n",
    "comparison_terms = list(terms_used)[:5]\n",
    "observed_expected = []\n",
    "for term in comparison_terms:\n",
    "    observed_expected.append(count_usage(term))\n",
    "\n",
    "observed_expected\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=0.40196284612688399, pvalue=0.52607729857054686),\n",
       " Power_divergenceResult(statistic=0.40196284612688399, pvalue=0.52607729857054686),\n",
       " Power_divergenceResult(statistic=0.40196284612688399, pvalue=0.52607729857054686),\n",
       " Power_divergenceResult(statistic=2.4877921171956752, pvalue=0.11473257634454047),\n",
       " Power_divergenceResult(statistic=0.40196284612688399, pvalue=0.52607729857054686)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "import numpy as np\n",
    "\n",
    "high_value_count = jeopardy[jeopardy[\"high_value\"] == 1].shape[0]\n",
    "low_value_count = jeopardy[jeopardy[\"high_value\"] == 0].shape[0]\n",
    "\n",
    "chi_squared = []\n",
    "for obs in observed_expected:\n",
    "    total = sum(obs)\n",
    "    total_prop = total / jeopardy.shape[0]\n",
    "    high_value_exp = total_prop * high_value_count\n",
    "    low_value_exp = total_prop * low_value_count\n",
    "    \n",
    "    observed = np.array([obs[0], obs[1]])\n",
    "    expected = np.array([high_value_exp, low_value_exp])\n",
    "    chi_squared.append(chisquare(observed, expected))\n",
    "\n",
    "chi_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
